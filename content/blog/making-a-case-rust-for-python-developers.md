+++
title = "Сделай выбор: Rust для разработчиков Python"
description = "Сделай выбор: Rust для разработчиков Python"
weight = 1
+++

SEEMS DAMAGED
[Перевод](https://medium.com/@rajasekar3eg/making-a-case-rust-for-python-developers-1a114e2d89f4)


Фото: Фотография Криса Рида на Unsplash

Я не мог придумать подходящее название для этой статьи. Простите за это. Разработчики Python включают в себя огромное количество разработчиков. Я собираюсь рассмотреть варианты использования для определенной группы разработчиков Python: разработчиков машинного обучения. Но и для других это может оказаться полезным. Под другими я имею в виду почти всех, кто приходит с языков GC высокого уровня, таких как Python, Go, Java и т. Д., Например, пройдите это обсуждение

Картина: Некоторые

Вам должно быть интересно, кто в здравом уме будет писать веб-приложения на Rust, якобы системном языке. Как только вы пройдете этап изучения Rust, который является относительно более крутым, вы поймете, что на самом деле это очень продуктивный язык. Помимо преимуществ в производительности, одна действительно недооцененная особенность Rust - это то, насколько элегантно он предотвращает целый класс распространенных ошибок в коде. После компиляции он, скорее всего, будет работать без каких-либо проблем в производственной среде при отсутствии логических ошибок в коде.
У Rust есть и неприятная сторона, особенно если вы используете типичные парадигмы из других языков ООП. Я оставлю этот момент, когда я должным образом представлю Rust в будущих статьях. А пока я сконцентрируюсь на Rust для обработки данных.

## Горе использования Python…

После доминирования R Python теперь, кажется, повсеместно используется в области машинного обучения. Я обожаю Python. Но каждый в какой-то момент проклял бы Python за его улитку, как скорость. Большинство библиотек машинного обучения и глубокого обучения в python фактически написаны на C, Fortran (numpy написано как на C, так и на fortran) или C++, поэтому они обычно обеспечивают очень хорошую производительность. Но проблема заключается в этапе предварительной обработки данных. Пока вы имеете дело с небольшими наборами данных, Pandas and Co. работают отлично. Когда размер данных увеличивается, люди выбирают разные пути, чтобы уменьшить проблему с производительностью.
Это еще более раздражает на этапе прототипирования, когда вы не можете угадать время выполнения определенных операций groupby или merge и тратите 1-2 часа на ожидание их завершения, но они не показывают никаких трэйтов завершения. Поэтому люди обычно прибегают к cython или pypy (что может быть неприменимо во многих ситуациях), чтобы ускорить процесс. Поверьте, иногда из-за быстрой разработки или из-за отсутствия у многих разработчиков машинного обучения опыта на производственном уровне многие из этих кодов, предназначенных для прототипирования, попадают в производственную фазу (еще одна большая тема, оставив ее для другого блога). Некоторые склонны отказываться от python и переходить на Spark, или это менее известный кузен Даск в самом python, который тратит немного денег на инфраструктуру кластера. Я считаю, что именно здесь Rust прекрасно дополняет Python.

## Знакомство с Rust…

Я долго изучал Rust из чистого интереса. Первоначально я никогда не использовал его для работы в офисе. Но однажды произошла интересная ситуация, когда я представил Rust своим коллегам.
Однажды мы анализировали дамп данных GitHub. Нам пришлось присоединить кучу файлов csv в этом дампе. Изначально нам нужно было присоединить следующие четыре файла. 

- project_topics.csv — 8.3 MB
- project_languages.csv — 5.1 GB
- projects.csv — 19.4 GB
- watchers.csv — 4.1 GB

Операции включают:
- проект _topics groupby на основе столбца repo_id и совокупного набора тем
- Предыдущий результат оставил соединение project_languages на «repo_id» и совокупный набор языков
- Предыдущий результат оставил присоединение к проектам на «repo_id» и получение основного языка
- Предыдущий результат оставил наблюдателей за присоединением на «repo_id» и совокупное количество наблюдателей.

Первые две операции можно довольно удобно выполнять в Pandas на машине с 16 ГБ. По какой-то странной причине, о которой мы не будем говорить, пиковое использование памяти увеличилось до 10 ГБ при подключении с помощью project_languages, хотя размер файла составляет всего 5 ГБ.
Для остальных операций панды явно не подходят. Поэтому мы решили использовать pyspark.
Здесь я получил возможность продемонстрировать полезность Rust. Я весело бросил вызов своему коллеге, что, прежде чем вы напишете искровой скрипт и получите из него результат, я закончу писать свой скрипт на Rust и получу результат.

Вот сценарий Pyspark:

Вот программа на Rust, которую я написал:

Вот время, необходимое для запуска обоих скриптов:

Spark time:
```
real    24m38.163s
user    0m0.335s //time couldn't capture the jvm process user stat
sys     0m0.088s
```

Rust time:
```
real    2m52.699s
user    2m34.125s
sys     0m12.078s
```

После того, как я получил результат, нам пришлось подождать 15 минут, чтобы получить результат от искрового скрипта. На написание кода на Rust у меня ушло чуть больше 5 минут. В коде Rust количество строк может быть больше, чем в искровом коде, но большинство из них - очень похожие функции с небольшими изменениями. Код на Rust получил результат всего за 2 минуты 52 секунды по сравнению с 24 минутами Spark. Я не занимался оптимизацией этого кода. Это настолько просто, насколько это возможно.
    
    Отказ от ответственности: я уже использовал Rust в подобных ситуациях несколько раз заранее. Поэтому у меня было очень четкое представление о том, что мне нужно сделать, еще до того, как я начал. У меня даже были необходимые шаблоны и файл cargo.toml. Вот почему мне потребовалось гораздо меньше времени, чтобы закончить этот сценарий за такое короткое время. Для других это может занять больше времени. Но, честно говоря, изучение искры и панд также требует времени у людей. Так что я считаю, что это справедливое сравнение.

## Удивительная лаконичность Rust…

Как видно из программы Rust, это довольно просто. Я использовал HashMap, эквивалент словаря Python для агрегирования. Я использовал HashSet для создания наборов тем и языков. Я прочитал файлы один за другим, выполнил требуемую операцию и передал хэш-карту следующей функции.
Это основная часть агрегирования. На самом деле это очень просто. 

```rs
 agg //hashmap
    .entry(id) //get the entry with key “id”
    .or_insert(aggregate::new()) // if the entry is not present, then insert the empty structure
    .topic_set //if the entry is present get the topic_set field from the aggregate structure
    .insert(topic); //insert the topic to the topic_set
```

Аналогичный код на Python будет выглядеть так:

```py
agg = dict()
if id in agg:
    agg[id][“topic_set”].add(topic)
else:
    agg[id] = { “topic_set”: set(), “language_set”: set(), “primary_language”: None, “watchers_count”: 0 }
    agg[id][“topic_set”].add(topic)
```

Как видите, на Rust довольно приятно писать с очень хорошими абстракциями высокого уровня, за исключением «&» и странных «to_owned», разбросанных здесь и там. Есть много мест, где я использовал «unwrap()». Это не идиоматический Rust. Мы позволяем программе завершиться всякий раз, когда возникает ошибка. Для простоты введения я использовал их здесь. Всегда полезно правильно обрабатывать ошибки. Эти концепции являются основной частью изучения Rust, и я рассмотрю их в следующих статьях.

В отличие от python, Rust - это статически типизированные языки. Это означает, что вы должны указать типы при написании кода. Но в отличие от Java и C, в Rust есть нечто, называемое выводом типа, которое будет угадывать тип везде, где это возможно. Как видно из кода, я указал типы только в сигнатурах функций. В теле функции Rust сам определяет необходимые типы. Это придает очень приятную привлекательность программе Rust в целом.

Если вы все еще не можете понять некоторые части кода, дайте мне знать в комментариях. Я постараюсь рассмотреть эти концепции в следующих сериях.

## Стоит ли оно того…

Вы можете спросить, нужно ли мне изучать Rust за эту разницу всего в 15 минут? Но я бы сказал, что эта разница увеличивается, когда вы собираетесь использовать еще большие наборы данных. Вы не всегда можете получить кластер Spark, особенно на этапе прототипирования. Однако иногда вам придется иметь дело с огромными данными. В этом случае, вместо того, чтобы переходить на C, C++, что отпугивает большинство разработчиков python, которых я видел, я думаю, что Rust предоставляет гораздо лучшую альтернативу. Вдобавок, если вы хотите написать высокопроизводительную библиотеку для python, до сих пор наиболее популярным выбором является C. Но с превосходными возможностями FFI в Rust, его потрясающими абстракциями и экосистемой вы можете быть намного более продуктивными при написании библиотек.

Если посмотреть на это, программа на Rust примерно в 8,5 раза быстрее. Разница становится глубокой, когда размер набора данных увеличивается. Позвольте мне показать вам еще один пример, который подчеркивает эту разницу.

Я получил кучу данных для анализа по одному POC, над которым я работал. Я получил 4 tar-файла, собранных за 4 дня, объемом данных 5,5 ГБ. Когда я их извлек, оказалось, что это колоссальные 128 ГБ. Очевидно, в этих файлах должно быть много избыточности. Я решил проанализировать данные первого дня, которые были самыми маленькими: 43 файла и всего 9 ГБ. Я не могу предоставить подробные данные по очевидным причинам. Но суть проблемы я могу раскрыть.

В каждом CSV-файле было 9 столбцов. Мне пришлось выполнить групповую операцию с 3 столбцами и закрыть столбец с меткой времени в течение 30 минут и получить сумму другого столбца. Если бы это был просто groupby, я мог бы использовать функцию pandas chunk, и это должно было быть очень быстро. Но были и некоторые операции по объединению. Поэтому мне пришлось искать другие варианты. Я снова выбрал Spark и Rust.

Давайте сравним код и результаты (вы можете попробовать воспроизвести результаты, создав фиктивные данные для следующего кода): 

Spark code:

Rust code:

Spark time:
```
real    20m8.024s
user    0m0.304s
sys     0m0.051s
```

Rust time:
```
real 1m37.523s
user 4m11.576s
sys 0m9.232s
```

Опять же, в моей машине 12-кратное ускорение по сравнению со Spark. Это тривиально распараллеливаемая логика. Поэтому я использовал замечательную функцию par_iter() из библиотеки Rayon, чтобы распараллелить процесс. Вот почему «реальное» время меньше «пользовательского». Есть множество способов оптимизировать искру, чтобы сделать ее немного быстрее. Даже тогда результаты были столь же ошеломляющими. А теперь представьте разницу во времени для данных объемом 128 ГБ в целом. Предполагая линейную шкалу, 23 минуты против 286 минут.

### Примечание:
На что стоит обратить внимание. При работе на жестком диске код Rust работал немного медленнее. Например, посмотрите результат времени для первого кода Rust, когда файлы были прочитаны с жесткого диска. 

```
real    5m7.349s
user    4m17.373s
sys     0m4.444s
```

Реальное время намного выше, чем пользовательское + системное время, несмотря на то, что оно многопоточное. Это говорит нам о том, что большую часть времени ЦП просто ждал ввода-вывода файла. Файловый ввод-вывод не успевал за скоростью обработки. Здесь процесс интенсивного ввода-вывода. Вот верхний экран процесса Rust.

Изображение: экран htop при запуске кода Rust

Как видите, процесс Rust использовал только 30% ЦП. Таким образом, при переходе на SSD «реальное» время стало почти равным времени «пользователь + системное», и процесс стал интенсивным для ЦП. Однако такого же ускорения не наблюдалось для кода Spark. Что касается самого жесткого диска, загрузка ЦП была чрезмерной.

Изображение: верхний экран при запуске кода Spark

## Последние мысли…

Я не считаю, что вы всегда должны использовать Rust вместо Spark. Spark - очень мощный зверь, когда дело касается распределенной обработки. Но для данных, которые удобно помещаются на одной машине, C/C++ / Rust, скорее всего, будет намного быстрее. Чтобы преодолеть накладные расходы, связанные с распределенными фреймворками, вам понадобится много машин для достижения скорости, аналогичной скорости одиночного машинного кода. Аналогичное мнение высказал в своей статье Фрэнк МакШерри. Пожалуйста, прочтите следующую статью. Это дает интересные идеи.

Что касается продуктивности, вы можете видеть, что код на Rust довольно прост в написании. Для типичных операций соединения и группировки логика очень похожа на ту, что мы видели ранее. Вы можете повторно использовать один и тот же код во многих ситуациях.

На мой взгляд, Rust легко доступен для людей, пришедших из языков программирования высокого уровня, по сравнению с C/C++. Это делает написание кода низкого уровня таким же простым, как языки высокого уровня, если используются надлежащие абстракции. В следующей серии статей я попытаюсь представить Rust с упором на продуктивность и на то, как избежать распространенных ошибок и отчаяния, которые обычно сопровождаются изучением Rust в первый раз. 